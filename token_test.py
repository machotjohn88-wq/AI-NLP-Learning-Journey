import nltk
from nltk.tokenize import word_tokenize

text = "I love studying Artificial Intelligence and NLP"

tokens = word_tokenize(text)

print(tokens)
